import os
import time
import tempfile
import numpy as np
import webrtcvad
import torchaudio
from pyannote.audio import Pipeline
from dotenv import load_dotenv
from scipy.io.wavfile import write as wav_write
from openai import OpenAI

# -------------------
# åƒæ•¸è¨­å®š
# -------------------
CHUNK_DURATION = 0.5  # æ¯æ®µ 0.5 ç§’
SAMPLE_RATE = 16000
VAD_MODE = 3          # æœ€åš´æ ¼
MIN_SPEECH_DURATION = 1.5  # è¶…é 1.5 ç§’æ‰é€å‡ºè¾¨è­˜
LANGUAGE = "zh"

# -------------------
# ç’°å¢ƒè®Šæ•¸èˆ‡æ¨¡å‹åˆå§‹åŒ–
# -------------------
load_dotenv()
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
hf_token = os.getenv("HUGGINGFACE_TOKEN")
os.environ["HF_TOKEN"] = hf_token
vad = webrtcvad.Vad(VAD_MODE)
diarization_pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization", use_auth_token=hf_token)

# -------------------
# å·¥å…·å‡½æ•¸
# -------------------
def load_audio_chunks(wav_path):
    waveform, sr = torchaudio.load(wav_path)
    if sr != SAMPLE_RATE:
        waveform = torchaudio.functional.resample(waveform, sr, SAMPLE_RATE)
    audio = waveform[0].numpy()
    chunk_size = int(CHUNK_DURATION * SAMPLE_RATE)
    return [audio[i:i + chunk_size] for i in range(0, len(audio), chunk_size)]

def float32_to_pcm16(audio_float):
    audio_float = np.clip(audio_float, -1, 1)
    return (audio_float * 32767).astype(np.int16).tobytes()

def is_speech(chunk, sample_rate=SAMPLE_RATE, threshold=0.5):
    """
    åˆ¤æ–· chunk ä¸­èªéŸ³æ¯”ä¾‹æ˜¯å¦è¶…é thresholdã€‚
    å›å‚³ True è¡¨ç¤ºæ˜¯èªéŸ³æ®µï¼ŒFalse è¡¨ç¤ºä¸æ˜¯ã€‚
    """
    if not isinstance(chunk, np.ndarray) or chunk.dtype != np.float32:
        raise ValueError("Input chunk must be float32 numpy array.")

    pcm = float32_to_pcm16(chunk)

    frame_duration = 30  # æ¯å°æ®µ 30ms
    frame_size = int(sample_rate * frame_duration / 1000)  # 480 samples
    byte_size = frame_size * 2  # æ¯ sample 2 bytes

    num_frames = len(pcm) // byte_size
    if num_frames == 0:
        return False

    speech_count = 0

    for i in range(num_frames):
        start = i * byte_size
        end = start + byte_size
        frame = pcm[start:end]
        if len(frame) < byte_size:
            continue
        try:
            if vad.is_speech(frame, sample_rate):
                speech_count += 1
        except webrtcvad.Error:
            continue  # é¿å… VAD ç•°å¸¸é€ æˆä¸­æ–·

    speech_ratio = speech_count / num_frames
    # print(f"ğŸ” èªéŸ³æ¯”ä¾‹: {speech_ratio:.2f}")
    return speech_ratio >= threshold


def transcribe_streaming(chunks):
    buffer = []
    sentence_id = 0

    for i, chunk in enumerate(chunks):
        print(f"â³ æ¨¡æ“¬ä¸²æµå‚³å…¥ç¬¬ {i+1} æ®µ...")

        if is_speech(chunk):
            buffer.append(chunk)
        else:
            if len(buffer) * CHUNK_DURATION >= MIN_SPEECH_DURATION:
                sentence_id += 1
                audio_segment = np.concatenate(buffer)
                buffer = []

                with tempfile.NamedTemporaryFile(suffix=".wav", delete=True) as tmpfile:
                    wav_write(tmpfile.name, SAMPLE_RATE, (audio_segment * 32768).astype(np.int16))

                    with open(tmpfile.name, "rb") as f:
                        response = openai_client.audio.transcriptions.create(
                            model="whisper-1",
                            file=f,
                            language=LANGUAGE
                        )
                        print(f"\nğŸ—¨ ç¬¬ {sentence_id} å¥è½‰è­¯çµæœï¼š{response.text.strip()}")
            else:
                buffer = []

        time.sleep(CHUNK_DURATION)

def speaker_diarization(wav_path):
    print("\nğŸ§‘â€ğŸ¤â€ğŸ§‘ èªè€…åˆ†é›¢åˆ†æä¸­...")
    result = diarization_pipeline(wav_path)
    for turn, _, speaker in result.itertracks(yield_label=True):
        print(f"{turn.start:.1f}s - {turn.end:.1f}s: {speaker}")

# -------------------
# ä¸»ç¨‹å¼
# -------------------
def main():
    wav_path = "./shorts.wav"
    print("ğŸ”Š é–‹å§‹æ¨¡æ“¬ä¸²æµèªéŸ³è¾¨è­˜...\n")
    chunks = load_audio_chunks(wav_path)
    transcribe_streaming(chunks)
    speaker_diarization(wav_path)

if __name__ == "__main__":
    main()
