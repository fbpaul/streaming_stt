import torchaudio
import time
import sys

from configs.config import SAMPLE_RATE, CHUNK_DURATION, vad, FILE
from utils.vad import split_audio_to_chunks
# from transcriber.transcriber_openai import StreamingTranscriber
from transcriber.transcriber import StreamingTranscriber

def main():
    wav_path = FILE
    waveform, sr = torchaudio.load(wav_path)
    if sr != SAMPLE_RATE:
        waveform = torchaudio.functional.resample(waveform, sr, SAMPLE_RATE)

    audio = waveform[0].numpy()
    chunks = split_audio_to_chunks(audio, SAMPLE_RATE, CHUNK_DURATION)

    transcriber = StreamingTranscriber(vad)

    print("ğŸ”Š é–‹å§‹æ¨¡æ“¬ä¸²æµè¾¨è­˜...\n")
    interim_text = ""
    interim_active = False

    for i, chunk in enumerate(chunks):
        # print(f"è™•ç†ç¬¬ {i+1} å€‹ç‰‡æ®µ...")
        result = transcriber.process_chunk(chunk)
        if result:
            if result["type"] == "interim":
                interim_text += result["text"]
                sys.stdout.write("\r")  # å›åˆ°è¡Œé¦–
                sys.stdout.write(f"â³ [æš«å®š] {interim_text[:80]}")  # é¡¯ç¤ºå‰ 80 å­—
                sys.stdout.flush()
                interim_active = True

            elif result["type"] == "final":
                if interim_active:
                    sys.stdout.write("\r" + " " * 100 + "\r")  # æ¸…é™¤æš«å®šè¡Œ
                print(f"âœ… [ä¿®æ­£] ({result['speaker']}) {result['start']}~{result['end']}s: {result['text']}")
                interim_text = ""
                interim_active = False

        time.sleep(CHUNK_DURATION)

if __name__ == "__main__":
    main()
