import torchaudio
import time
from config import SAMPLE_RATE, CHUNK_DURATION, vad
from vad import split_audio_to_chunks
from transcriber import StreamingTranscriber

def main():
    # è¼‰å…¥éŸ³è¨Šæª”
    wav_path = "./shorts.wav"
    waveform, sr = torchaudio.load(wav_path)
    if sr != SAMPLE_RATE:
        waveform = torchaudio.functional.resample(waveform, sr, SAMPLE_RATE)

    audio = waveform[0].numpy()
    chunks = split_audio_to_chunks(audio, SAMPLE_RATE, CHUNK_DURATION)

    # åˆå§‹åŒ– transcriber
    transcriber = StreamingTranscriber(vad)

    print("ğŸ”Š é–‹å§‹æ¨¡æ“¬ä¸²æµè¾¨è­˜...\n")

    # æ¨¡æ“¬ä¸²æµé€æ®µé€å…¥
    for i, chunk in enumerate(chunks):
        result = transcriber.process_chunk(chunk)
        if result:
            if result["type"] == "interim":
                print(f"â³ [æš«å®š] {result['text']}")
            elif result["type"] == "final":
                print(f"âœ… [ä¿®æ­£] ({result['speaker']}) {result['start']}~{result['end']}s: {result['text']}")
        time.sleep(CHUNK_DURATION)

if __name__ == "__main__":
    main()
